---
title: "Tipologia i cicle de vida de les dades"
subtitle: "Pràctica 2"
author: "Esther Ruano, Carles Ventura"
date: "2025-05"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: 
toc-title: "Índex"
---

# Introducció

Aquesta és la segona pràctica per equips de l'assignatura de Tipologia i cicle de vida de les dades. En aquesta pràctica prendrem un conjunt de dades i les estudiarem: en primer lloc, haurem d'analitzar la seva estructura i entendre quina forma tenen les dades, seguidament, triarem una variable objectiu i intentarem predir-la amb un sistema d'aprenentatge supervisat. Finalment, triarem un sistema no supervisat per estudiar les dades. Amb això, haurem aconseguit estudiar les dades i presentarem els resultats en forma de gràfica. 

Per realitzar aquesta pràctica, em triat un dataset de kaggle anomenat [Student Depression Dataset](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset), que ens ha cridat l'atenció ja que conté informació sobre l'estat mental de més de vint-i-cinc mil estudiants. A més, aquest dataset conté columnes de tota mena: categòriques, numèriques, geogràfiques... i ens permetrà treballar amb molts escenaris diferents. Prendrem la variable booleana `Depression_Status` com a variable objectiu, i la intentarem predir amb el nostre model supervisat. Finalment, també aplicarem contrast d'hipòtesi per respondre a la nostra pregunta de recerca:

> Depèn la distribució de la depressió del gènere?

I la respondrem formulant la hipòtesi de que són iguals i aplicant contrast d'hipòtesis sobre:

$$
H_0 : p_{home} = p_{dona}
$$

Abans de començar amb el codi, instal·lem i importem les llibreries que farem servir:

```{r setup}
# Instal·lacio de paquets
# install.packages("caret")
# install.packages("cluster")
# install.packages("corrplot")
# install.packages("data.table")
# install.packages("dplyr")
# install.packages("factoextra")
# install.packages("ggplot2")
# install.packages("gridExtra")
# install.packages("kableExtra")
# install.packages("mltools")
# install.packages("patchwork")
# install.packages("randomForest")
# install.packages("tidyverse")

## Carregar les llibreries
library(caret)
library(cluster)
library(corrplot)
library(data.table)
library(dplyr)
library(factoextra)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(mltools)
library(patchwork)
library(randomForest)
library(tidyverse)
```

# 1. Carregar i preparar les dades

Per tal de carregar les dades hem descarregat l'arxiu `csv` del [dataset triat](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset) i l'hem desat a la carpeta `/data`. Si inspeccionem l'arxiu veiem que la primera fila correspon als noms de les columnes i que el separador usat és ",". Per llegir les dades fem servir la funció [`read.csv`](https://www.rdocumentation.org/packages/COVID19/versions/2.0.3/topics/read.csv) i indiquem que volem prendre la primera fila com a headers i també marquem `stringsAsFactors = FALSE`: no s'aconsella convertir les cadenes a factors, ja que en dificulta el tractament posterior i pot generar errors [[font](https://blog.r-project.org/2020/02/16/stringsasfactors/)]. Seguidament, en mostrem les primeres línies amb la funció `head()` per fer-ne una primera avaluació.

Per tal de mostrar la taula, darem servir la llibreria [kableExtra](https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html#Overview). 

```{r}
df <- read.csv("data/student_depression_dataset.csv", stringsAsFactors = FALSE, sep = ",")

print(paste("Mida del dataset: ", nrow(df), " files i ", ncol(df), " columnes."))

kbl(head(df), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

El dataset triat té les següents columnes, i han recollit valors per gairebé vint-i-vuit mil persones:

* **`id`:** és un identificador numèric per cada usuari.
* **`Gender`:** indica el gènere de cada usuari.                          
* **`Age`:** és l'edat de cada persona del dataset.
* **`City`:** ciutat de residència de la persona entrevistada.                                 
* **`Profession`:** feina a la qual es dediquen.
* **`Academic.Pressure`:** nivell de pressió acadèmica a la que estan sotmesos.                
* **`Work.Pressure`:** nivell de pressió laboral a la que estan sotmesos.  
* **`CGPA`:** nota mitjana acumulada de cada estudiant.                                
* **`Study.Satisfaction`:** nivell de satisfacció amb els estudis.
* **`Job.Satisfaction`:** nivell de satisfacció amb la feina.                    
* **`Sleep.Duration`:** hores que dormen cada dia, de mitja.
* **`Dietary.Habits`:** descriu com de saludables són els seus hàbits alimenticis.
* **`Degree`:** el nivell d'estudis que estan estudiant.
* **`Have.you.ever.had.suicidal.thoughts..`:** és una variable booleana que indica si algun cop han tingut pensaments suicides.
* **`Work.Study.Hours`:** quantitat d'hores mitjana dedicada a estudiar o treballar.
* **`Financial.Stress`:** nivell d'estrès econòmic al qual estan sotmesos.
* **`Family.History.of.Mental.Illness`:** indica si la seva família té un històric de malalties mentals.
* **`Depression`:** Indica, de manera booleana, si experimenta o no depressió.

# 2. Anàlisi explorativa de les dades

A continuació volem entendre com es distribueixen les dades i si tenen alguna anomalia. Comencem investigant com son aquestes dades i identificant els rangs de valors, els diferents valors en cada categoria i la quantitat de nuls que trobem. Això ho aconseguim mitjançant les funcions [`summary`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/summary), [`is.na`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/NA) i [`unique`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unique). Per mostrar-los, de nou, fem servir kableExtra. A més, creem una llista amb les columnes numèriques i una altra amb les categòriques, que ens serà útil més endavant, sense incloure l'id dels usuaris. És interessant destacar que `Sleep.Duration` són intervals i, per tant, es proporciona com a informació categòrica, amb 5 rangs possibles, com veurem a continuació. A més, `Financial.Stress` està sent interpretada com a caràcter:

```{r}
print(paste("Financial.Stress és de tipus: ", class(df[["Financial.Stress"]])))
print(paste("Financial.Stress pren els valors: ", unique(df[["Financial.Stress"]])))
```

Per tant, el transformem en numèric i deixarem els valors "?" com en `NA`.

```{r}
df$Financial.Stress[df$Financial.Stress == "?"] <- NA 
df$Financial.Stress <- as.numeric(df$Financial.Stress)  
```

Observem que la variable `Depression` és numèrica; tot i això, representa una categoria booleana. Tanmateix, decidim deixar que sigui numèrica ja que en els models supervisats, podrem fer servir una regressió i després decidir la categoria comparant aquest valor amb 0.5.

Seguidament, eliminem la columna d'`id` ja que no ens proporciona cap informació:

``` {r}
df <- df %>% select(-id)
```

Finalment, comprovem quantes columnes tenen valors nuls:

```{r}
kbl(t(colSums(is.na(df))), booktabs = TRUE, caption="Quantitat de dades buides") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Veiem que hi ha només tres valors nuls, en la columna `Financial.Stress` cosa positiva; més endavant decidirem com fer-ne imputació. Ara, per analitzar la resta del dataset en detall; separem aquest apartat en dades qualitatives i quantitatives:

```{r}
categorical_columns <-c("Gender", "City", "Profession", "Sleep.Duration", "Dietary.Habits", "Degree", "Have.you.ever.had.suicidal.thoughts..", "Family.History.of.Mental.Illness")
numerical_columns <- c("Age", "Academic.Pressure", "Work.Pressure", "CGPA", "Study.Satisfaction", "Job.Satisfaction", "Work.Study.Hours", "Financial.Stress", "Depression")
```

# 2.1. Anàlisi explorativa de les dades quantitatives

```{r}
kbl(summary(df[, numerical_columns]), booktabs = TRUE, caption="Resum de les dades numèriques") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Si mirem les variables numèriques, observem el següent:

* Pel que fa a l'edat, sembla que hi ha un gran salt entre el tercer quartil i el màxim (vint-i-nou anys); així que segurament trobem alguns valors extrems (__outliars__) aquí. 
* Les columnes que indiquen satisfacció prenen valors entre 0 i 5, i volem destacar com `Job.Satisfaction` té una mitja de 0.000681 i una mediana de 0, valors molt molt baixos. 
* Els valors d'hores d'estudi i feina diàries són entre 0 i 12, amb un rang gran al primer quartil, però cap valor que sembli invàlid.

A continuació mostrem `boxplots` i histogrames per les dades numèriques, per entendre millor la seva distribució. Per aconseguir-ho, farem servir la llibreria `ggplot2`, que incorpora totes les gràfiques, i la llibreria `gridExtra`, que ens permet endreçar-les. Ajustem les mides amb `fig.height=20, fig.width=15` per tal que a l'html generat es vegin bé


```{r, fig.height=20, fig.width=15}
histograms <- list()
boxplots <- list()

for (col in numerical_columns) {
  
  # Histogram
  histograms[[length(histograms) + 1]] <-  ggplot(df, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "white") +
    ggtitle(paste("Histograma de", col))
  
  # Boxplot
  boxplots[[length(boxplots) + 1]] <- ggplot(df, aes_string(y = col)) +
    geom_boxplot(fill = "tomato", outlier.colour = "red", outlier.shape = 16) +
    ggtitle(paste("Boxplot de", col))
}

do.call(grid.arrange, c(histograms, ncol = 3))
do.call(grid.arrange, c(boxplots, ncol = 3))
```

Mirant els histogrames, i boxplots, observem el següent:

* Hi ha columnes que, tot i ser numèriques, només prenen un conjunt de valors molt petits: `Academic.Pressure`, `Work.Pressure`, `Study.Satisfaction`, `Job.Satisfaction` i `Financial.Stress` prenen valors en cinc o sis nivells.
* Les columnes d'edat (`Age`) i nota mitja (`CGPA`) tenen outilars molt pronunciats; ho veiem en els punts que queden fora dels bigotis dels Boxplots.
* La variable objectiu, `Depression`, només pren valors zero i u; i trobem que hi ha aproximadament cinc-mil instàncies més d'usuaris deprimits que no deprimits. Això pot provocar que els nostres models tendeixin a predir `Depression=1`:

```{r}
print(paste("Quantitat de files amb Depression 1 (Yes):", sum(df$Depression == 1)))
print(paste("Quantitat de files amb Depression 0 (No):", sum(df$Depression == 0)))
print(paste("Un model que predís sempre Depression=1 tindria un accuracy = ", sum(df$Depression == 1) / nrow(df) ))
```
Ja que si un model només predís `Depression=1` ja tindria, gairebé, un 0.6% d'accuracy. Per tant, és probable que haguem d'utilitzar estratègies per reduir els falsos positius en els nostres models supervisats.

A més, podem estudiar la correlació entre les variables numèriques:

```{r}
cor_matrix <- cor(df[, numerical_columns], use = "complete.obs", method = "pearson")
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8)
```

Sembla que `Work.Pressure` està relacionat de manera forta i positiva amb `Job.Satisfaction`. Això pot semblar contraintuitiu, ja que sembla indicar que, com més pressió es pateix a la feina, més satisfets estan els usuaris. Per altra banda, la majoria d'usuaris han marcat 0 en ambdues categories:

```{r}
print(paste("Quantitat de files amb Work.Pressure diferent de 0:", sum(df$Work.Pressure != 0)))
print(paste("Quantitat de files amb Job.Satisfaction diferent de 0:", sum(df$Job.Satisfaction != 0)))
print(paste("Quantitat de files amb Work.Pressure i Job.Satisfaction diferent de 0:", sum(df$Job.Satisfaction != 0 & df$Work.Pressure != 0)))
```
I veiem que, dels més de vint-i-set mil, molt pocs usuaris han marcat valors diferents de 0 en aquestes categories (tres i vuit, respectivament), i que tots aquells que han marcat `Work.Pressure` diferent de 0, també han marcat `Job.Satisfaction` diferent de zero. Per tant, aquesta correlació ens diu poc.

Per altra banda, sembla que `Academic.Pressure` té una correlació forta i positiva amb la depressió dels usuaris, i que `Financial.Stress` també, seguida de `Work.Study.Hours`. Per acabar, sembla que l'edat té una correlació negativa amb la depressió: com més joves, més propenços a estar deprimits. `Study.Satisfaction` també hi té una correlació negativa: sembla que, com més satisfets estan amb els seus estudis, menys possibilitats tenen d'estar deprimits. A diferènia de `Job.Satisfaction` i `Work.Pressure` veiem en els histogrames que `Academic.Pressure` i `Study.Satisfaction` prenen valors variats i diversos; per tant, aquesta correlació si que ens pot indicar tendències que veurem més endavant en els nostres models.

# 2.3. Anàlisi explorativa de les dades qualitatives

Ara, volem explorar quins valors prenen les variables quantitatives:

```{r}
categorical_values <- sapply(df[, categorical_columns], function(col) paste(unique(col), collapse = ", "))
categorical_df <- data.frame(Variable = names(categorical_values), Unique_Values = unname(categorical_values))

kbl(categorical_df, booktabs = TRUE, caption="Dades categòriques", colnames=categorical_columns) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Trobem que hi ha 5 rangs pel que fa a les hores de son, i quatre per als hàbits alimentaris; i ambdues categories contenen `Others` com a opció. En apartats següents discutirem si ho considerem opció no vàlida i la imputem, o si seguim endavant amb la categoria. El mateix passa amb `Degree`.

Per tractar les variables categòriques, n'haurem de fer _one-hot_ encoding; potencialment utilitzant la funció [`one-hot`](https://www.rdocumentation.org/packages/mltools/versions/0.3.5/topics/one_hot) que proporciona R; i ho farem a l'apartat 3. Per a estudiar-les de manera explorativa mostrem amb `barplots` la distribució de cada una de les variables no-numèriques.

```{r, fig.height=25, fig.width=15}
barplots <- list()

for (col in categorical_columns) {
  # Barplot
  barplots[[length(barplots) + 1]] <- ggplot(df, aes_string(x = col)) +
          geom_bar(fill = "orange") +
          ggtitle(paste("Bar plot de", col)) +
          theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
          coord_flip()
}

do.call(grid.arrange, c(barplots, ncol = 2))
```

Si mirem les variables qualitatives, veiem el següent:

* La quantitat d'homes i dones que han participat a l'estudi és gairebé igual.
* A simple vista, les ciutats no mostren cap tendència.
* La majoria dels entrevistats, com indica el nom del dataset, són estudiants:

```{r}
print(paste("Quantitat d'estidiants:", sum(df$Profession == "Student")))
print(paste("Percentatge d'estidiants:", sum(df$Profession == "Student") / nrow(df)))
```

* Pel que fa a `Sleep.Duration` i `Dietary.Habits` totes les categories tenen quantitats comparables de respostes, llevat de `Others`, que en té molt poques.
* El grau més comú és `Class 12`, que és l'últim any d'insititut.
* Dos terços dels entrevistats han tingut pensaments suicides.
* Pel que fa a l'històric de malaltis mentals a la família, aproximadament la meitat dels entrevistats han respost que sí.

# 3. Neteja de les dades

En aquest apartat prestarem atenció a quines anomalies tenen les nostres dades i decidirem com gestionar-les

## 3.1 Imputació

En els apartats anteriors hem vist les següents variables amb valors problemàtics:

* **`Financial.Stress`:** aquesta variable és numèrica i pren valor `NA` tres cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Financial.Stress = 'NA':", sum(is.na(df$Financial.Stress))))
```

En aquest cas, la variable `Financial.Stress` és numèrica i pren només valors enters; tenint en compte la petita quantitat de valors no vàlids la reemplaçem amb la mediana, ja que la mitjana pot ser decimal.

```{r}
df$Financial.Stress[is.na(df$Financial.Stress)] <- median(df$Financial.Stress, na.rm = TRUE)
print(paste("Quantitat de files amb Financial.Stress = 'NA':", sum(is.na(df$Financial.Stress))))
```
* **`Sleep.Duration`:** aquesta variable és categòrica i pren valor `Others` divuit cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Sleep.Duration = 'Others':", sum(df$Sleep.Duration == "Others")))
```

Les opcions de la categoria `Sleep.Duration` són quatre intervals que cobreixen tota la recta real; per tant, el valor `Others` no té sentit. Decidim, en aquest cas, imputar-lo amb el valor més comú, ja que la dada no és quantitativa sinó qualitativa.

```{r}
most_common_sleep_duration <- names(which.max(table(df$Sleep.Duration)))
df$Sleep.Duration[df$Sleep.Duration == "Others"] <- most_common_sleep_duration
print(paste("Quantitat de files amb Sleep.Duration = 'Others':", sum(df$Sleep.Duration == "Others")))
```
* **`Dietary.Habits`:** aquesta variable és categòrica i pren valor `Others` dotze cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Dietary.Habits = 'Others':", sum(df$Dietary.Habits == "Others")))
```

Les opcions de la categoria `Dietary.Habits` són tres nivells segons com de saludables són; per tant, el valor `Others` no té sentit. Decidim, en aquest cas, imputar-lo amb el valor més comú, ja que la dada no és quantitativa sinó qualitativa.

```{r}
most_common_dietary_habits <- names(which.max(table(df$Dietary.Habits)))
df$Dietary.Habits[df$Dietary.Habits == "Others"] <- most_common_dietary_habits
print(paste("Quantitat de files amb Dietary.Habits = 'Others':", sum(df$Dietary.Habits == "Others")))
```
* **`Degree`:** aquesta variable és categòrica i pren valor `Others` trenta-cinc cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Degree = 'Others':", sum(df$Degree == "Others")))
```

En aquest cas, però, tot i que la llista d'opcions educatives proporcionades és prou exhaustiva, pot haver-hi usuaris que no encaixin en cap categoria i, per tant, considerem que el valor `Others` és vàlid en aquest context i no realitzem imputació.


## 3.2 Eliminar outliars

Utilitzant els boxplots per avaluar les variables numèriques, trobem que l'edat (`Age`) i nota mitjana `CGPA` tenen outliars molt marcats; per tant, els eliminarem fent servir la tècnica del [rang interquartílic](https://es.wikipedia.org/wiki/Rango_intercuart%C3%ADlico).

```{r outlier-removal}
for (col in c("Age", "CGPA")) {
  Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)
  Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  df <- df[df[[col]] >= lower_bound & df[[col]] <= upper_bound, ]
}
```

Observem com la seva distribució ha canviat:

```{r, fig.height=8, fig.width=15}
histograms <- list()
boxplots <- list()

for (col in c("Age", "CGPA")) {
  
  # Histogram
  histograms[[length(histograms) + 1]] <-  ggplot(df, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "white") +
    ggtitle(paste("Histograma de", col))
  
  # Boxplot
  boxplots[[length(boxplots) + 1]] <- ggplot(df, aes_string(y = col)) +
    geom_boxplot(fill = "tomato", outlier.colour = "red", outlier.shape = 16) +
    ggtitle(paste("Boxplot de", col))
}

do.call(grid.arrange, c(histograms, ncol = 3))
do.call(grid.arrange, c(boxplots, ncol = 3))
```

## 3.3 Transformar variables categòriques

Per tal de treballar amb les variables categòriques, farem [one-hot encoding](https://es.wikipedia.org/wiki/One-hot), ja que és el més aconsellable per a entrenar models després. Farem servir el mètode [`one_hot`](https://www.rdocumentation.org/packages/mltools/versions/0.3.5/topics/one_hot) de la llibreria `mltools`. Consultem la documentació per veure que primer cal transformar-la en una `df.table` i, després, podem aplicar el mètode i mostrar les primeres files del dataset.

```{r}
df <- as.data.table(df)

for (col in categorical_columns) {
  df[[col]] <- as.factor(df[[col]])
}

df_encoded <- one_hot(df, cols = categorical_columns)

kbl(head(df_encoded), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Comprovem que s'han codificat correctament

# 4. Anàlisi de dades

## 4.1 Model supervisat

En aquest apartat intentarem predir la columna `Depression`, que és categòrica, però només pren els valors 0 i 1. Ho farem de dues maneres:

* Per una banda, com que la columna és numèrica, aplicarem una regressió lineal, ja que la matriu de correlació indica que hi ha algunes variables, com ara la pressió acadèmica, tenen una forta relació lineal amb la variable objectiu. La regressió predirà un valor que nosaltres compararem amb 0.5; si és major, triarem "1" com a valor predit i, en cas contrari, triarem "0".

* Per altra banda, farem servir un Random Forest, que és un model supervisat molt comú per a variables categòriques que combina diversos arbres de decisió per predir les variables objectiu.

### 4.1.1 Partició Train/Test

El primer pas és separar el conjunt de dades entre les que farem servir per entrenar i les que usarem per avaluar; això ho farem utilitzant [createDataPartition](https://www.rdocumentation.org/packages/caret/versions/7.0-1/topics/createDataPartition). Triem el paràmetre `p = 0.8` de manera que farem servir un 80% de les dades per entrenar, i la resta per l'avaluació. A més, per tal que els nostres resultats siguin reproduibles, fixem la `seed` a 100, i mostrem les mides dels datasets resultants.

```{r}
set.seed(100)

train_index <- createDataPartition(df_encoded$Depression, p = 0.8, list = FALSE)

df_train <- df_encoded[train_index, ]
df_test <- df_encoded[-train_index, ]

print(paste("Mida del conjunt d'entrenament: ", nrow(df_train), " files i ", ncol(df_train), " columnes."))
print(paste("Mida del conjunt de test: ", nrow(df_test), " files i ", ncol(df_test), " columnes."))
```
Comprovem que s'han separat com esperàvem.

### 4.1.2 Regressió lineal

Com hem explicat, farem servir regressió lineal per predir la columna `Depression` i després discretitzarem el resultat per tal que encaixi en una de les categories. Per fer-ho, fem servir la funció [`lm`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) d'R.

```{R}
lm_model <- lm(Depression ~ ., data = df_train)
pred_lm <- predict(lm_model, newdata = df_test)
pred_lm_class <- ifelse(pred_lm < 0.5, 0, 1)
```

Ara, compararem aquestes prediccions amb els valors reals; farem servir dues mesures: accuracy i una matriu de confusió. És important tenir en compte que en el conjunt de dades hi ha cinc-mil casos més de depressió que de no depressió, aproximadament; per tant, és probable que el nostre model es decanti a predir sí. Si veiem que això passa, podrem considerar fer servir alguna altra mesura com ara F1 o el [ràtio de falsos positius](https://en.wikipedia.org/wiki/False_positive_rate) per tal que s'adapti millor. També podriem considerar estratègies de sampling per fer la mostra més homogènia. En primer lloc, però, cal avaluar aquests resultats; ho farem fent servir la funció [`confusionMatrix`](https://rdrr.io/cran/caret/man/confusionMatrix.html) de la llibreria `caret`:

``` {r}
confusionMatrix(as.factor(pred_lm_class), as.factor(df_test$Depression))
```
Observem una accuracy de 0.84, prou bona, i la matriu de confusió ens indica que la quantitat de falsos positius és prou superior a la de falsos negatius; és a dir, el nostre model tendeix a predir "Depression=1" més del que seria ideal. Això ho podem intentar ajustar amb mètodes de sampling o canviant la mesura per la qual optimitzem.

> TODO

### 4.1.3 Random Forest

Ara, farem la predicció amb un [Random Forest](https://en.wikipedia.org/wiki/Random_forest), que ens permetrà veure relacions no lineals, ja que combina diferents arbres de precisió i, a més, sol donar bons resultats en dades mixtes com les que tenim. Farem servir la funció [`randomForest`](https://www.rdocumentation.org/packages/randomForest/versions/4.7-1.2/topics/randomForest) que ens proporciona R i ho avaluem de nou amb una matriu de confusió. Aprofitem per passar-li el paràmetre `importance = TRUE` i així poder entendre els resultats. També limitem el valor de `ntree` per sota del que pren per defecte (500) per tal d'agilitzar l'execució del codi. 

Ens adonem aque algunes columnes tenen caràcters problemàtics per al nostre arbre; així que canviem els seus noms utlilitzant [`make.names`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/make.names). A més, com que volem que l'arbre faci classificació i no predicció, hem de canviar la variable `Depression` a categòrica.


```{r}
colnames(df_train) <- make.names(colnames(df_train))
colnames(df_test)  <- make.names(colnames(df_test))
df_train$Depression <- as.factor(df_train$Depression)
df_test$Depression  <- as.factor(df_test$Depression)
```

Un cop preparat, entrenem el model i fem les prediccions.

```{r}
model_rf <- randomForest(Depression ~ ., data = df_train, ntree = 200, importance = TRUE)
pred_rf <- predict(model_rf, newdata = df_test)
```

Com que hem posat el paràmetre `importance = TRUE`, podem veure la importància de cada variable a més d'avaluar els resultats amb la nostra matriu de confusió.

```{r}
kbl(importance(model_rf), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")

confusionMatrix(pred_rf, df_test$Depression)
```

> TODO comentar resultats

## 4.2. Model no supervisat: clustering d'estudiants

### 4.2.1 Selecció de variables rellevants

```{r}
# Torno a carregar el dataset per estar 100% segur que no està contaminat
df <- read.csv("data/student_depression_dataset.csv")
# Normalitzar noms de columnes
colnames(df) <- make.names(colnames(df))

# Eliminar columna ID
df <- df %>% select(-id)

# Eliminar files on Degree és "'Class 12'" (Pot ser un error....)
df <- df %>% filter(Degree != "'Class 12'")

# Crear df_cluster amb les columnes seleccionades
df_cluster <- df %>%
  select(Gender, Age, Degree, Profession,
         Academic.Pressure, Work.Pressure,
         CGPA, Study.Satisfaction, Job.Satisfaction,
         Sleep.Duration, Dietary.Habits,
         Have.you.ever.had.suicidal.thoughts..,
         Work.Study.Hours, Financial.Stress,
         Family.History.of.Mental.Illness)

```

### 4.2.2 Codificació i escalat de dades
```{r}
# Separem les qualitatives i quantitatives
qual_cols <- c("Gender", "Profession", "Academic.Pressure", "Work.Pressure",
               "Study.Satisfaction", "Job.Satisfaction", "Dietary.Habits",
               "Have.you.ever.had.suicidal.thoughts..", "Financial.Stress",
               "Family.History.of.Mental.Illness", "Sleep.Duration")
num_cols <- c("Age", "CGPA", "Work.Study.Hours")

# Dummy només per a qualitatives
dummies <- dummyVars(" ~ .", data = df_cluster[, qual_cols])
df_dummies <- predict(dummies, newdata = df_cluster[, qual_cols]) %>% as.data.frame()

# Combinar les columnes numèriques amb les dummies
df_numeric <- df_cluster[, num_cols]
df_combined <- bind_cols(df_numeric, df_dummies)

# Normalitzar les columnes numèriques dins del dataframe combinat
df_scaled <- df_combined
df_scaled[, num_cols] <- scale(df_combined[, num_cols])
```

### 4.2.3 Mètode del colze per determinar k

```{r}
set.seed(321)
wss <- map_dbl(1:10, function(k) {
  kmeans(df_scaled, centers = k, nstart = 10)$tot.withinss
})

plot(1:10, wss, type = "b", pch = 19,
     xlab = "Nombre de clústers (k)",
     ylab = "Total Within Sum of Squares",
     main = "Mètode del colze")
```

### 4.2.4 Aplicació de k-means amb k = 4

```{r}
set.seed(123)
kmeans_model <- kmeans(df_scaled, centers = 4, nstart = 25)
df$cluster <- as.factor(kmeans_model$cluster)
```

### 4.2.5 Valors mitjans de les variables quantitatives de cada clúster

```{r}
df %>%
  group_by(cluster) %>%
  summarise(
    Age_mean = mean(Age, na.rm = TRUE),
    CGPA_mean = mean(CGPA, na.rm = TRUE),
    WorkStudy_mean = mean(Work.Study.Hours, na.rm = TRUE),
    n = n()
  )
```

### 4.2.6 Distribucions de variables qualitatives

```{r echo = FALSE}

# Depression
df %>%
  group_by(cluster, Depression) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Depression, y = prop, fill = Depression)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Depression per clúster")

# Pensaments suïcides
df %>%
  group_by(cluster, Have.you.ever.had.suicidal.thoughts..) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Have.you.ever.had.suicidal.thoughts.., y = prop, fill = Have.you.ever.had.suicidal.thoughts..)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Pensaments suïcides per clúster")

# Academic Pressure
df %>%
  group_by(cluster, Academic.Pressure) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Academic.Pressure, y = prop, fill = Academic.Pressure)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Academic Pressure per clúster")

# Financial Stress
df %>%
  group_by(cluster, Financial.Stress) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Financial.Stress, y = prop, fill = Financial.Stress)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Financial Stress per clúster")

# Family History of Mental Illness
df %>%
  group_by(cluster, Family.History.of.Mental.Illness) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Family.History.of.Mental.Illness, y = prop, fill = Family.History.of.Mental.Illness)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Family History of Mental Illness per clúster")

# Sleep Duration
df %>%
  group_by(cluster, Sleep.Duration) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Sleep.Duration, y = prop, fill = Sleep.Duration)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Sleep Duration per clúster")

# Hàbits alimentaris
df %>%
  group_by(cluster, Dietary.Habits) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Dietary.Habits, y = prop, fill = Dietary.Habits)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució dels hàbits alimentaris per clúster")

# Degree
df %>%
  group_by(cluster, Degree) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Degree, y = prop, fill = Degree)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Degree per clúster")


```

# 5 Contrast d'hipòtesis entre Gender i Depression

## 5.1 Carrego el dataset i mostro la proporcio Dones/Homes amb o sense Depressió

```{r }
# Torno a carregar el dataset per estar 100% segur que no està contaminat
df <- read.csv("data/student_depression_dataset.csv")
# Normalitzar noms de columnes
colnames(df) <- make.names(colnames(df))

# Trobar les proporcions de Dones/Homes amb o sense Depressió
df_prop <- df %>%
  group_by(Gender, Depression) %>%
  summarise(count = n()) %>%
  mutate(prop = count / sum(count))  # proporció dins de cada gènere

# Canvio els valors 0/1 per No/Sí
df_prop$Depression <- factor(df_prop$Depression, labels = c("No", "Sí"))
print(df_prop)

# Mostro el gràfic amb les proporcions Dones/Homes amb o sense Depressió
ggplot(df_prop, aes(x = Gender, y = prop, fill = Depression)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proporció de depressió segons el gènere",
       x = "Gènere",
       y = "Proporció (%)",
       fill = "Depressió") +
  scale_fill_manual(values = c("darkseagreen3", "indianred2")) +
  theme_minimal()
```

## 5.2 Contrast d'hipòtesis de dues proporcions 

Per analitzar si hi ha una associació entre el gènere i la presència de depressió, plantegem el següent contrast d'hipòtesis:

**Hipòtesi nul·la ($H_0$):**  
No hi ha diferències en la proporció de persones amb depressió entre homes i dones.

$$
H_0 : p_{home} = p_{dona}
$$

**Hipòtesi alternativa ($H_1$):**  
Hi ha una diferència significativa en la proporció de persones amb depressió entre homes i dones.

$$
H_1 : p_{home} \ne p_{dona}
$$
```{r }
# Persones amb depressió per gènere
depression_male <- sum(df$Gender == "Male" & df$Depression == 1)
depression_female <- sum(df$Gender == "Female" & df$Depression == 1)

# Total Homes/Dones
total_male <- sum(df$Gender == "Male")
total_female <- sum(df$Gender == "Female")

# Contrast d'hipòtesis de proporcions
test_resultat <- prop.test(
  x = c(depression_male, depression_female),
  n = c(total_male, total_female),
  correct = FALSE,
  conf.level = 0.95
)

print(test_resultat)
```

Com que el $p$-value obtingut (0.7644) és molt superior al llindar de significació ($\alpha = 0{,}05$), no es pot rebutjar la hipòtesi nul·la.

# Conclusions 

> TODO
