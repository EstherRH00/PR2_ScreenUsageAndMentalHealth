---
title: "Tipologia i cicle de vida de les dades"
subtitle: "Pràctica 2"
author: "Esther Ruano, Carles Ventura"
date: "2025-05"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: 
toc-title: "Índex"
---

# Introducció

Aquesta és la segona pràctica per equips de l'assignatura de Tipologia i cicle de vida de les dades. En aquesta pràctica prendrem un conjunt de dades i les estudiarem: en primer lloc, haurem d'analitzar la seva estructura i entendre quina forma tenen les dades, seguidament, triarem una variable objectiu i intentarem predir-la amb un sistema d'aprenentatge supervisat. Finalment, triarem un sistema no supervisat per estudiar les dades. Amb això, haurem aconseguit estudiar les dades i presentarem els resultats en forma de gràfica. 

Per realitzar aquesta pràctica, hem triat un dataset de kaggle anomenat [Student Depression Dataset](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset), que ens ha cridat l'atenció perquè conté informació sobre l'estat mental de més de vint-i-cinc mil estudiants. A més, aquest dataset conté columnes de tota mena: categòriques, numèriques, geogràfiques... i ens permetrà treballar amb molts escenaris diferents. Prendrem la variable booleana `Depression_Status` com a variable objectiu, i la intentarem predir amb el nostre model supervisat.

Plantegem, per tant, el problema d'entendre quins factors influeixen més en la depressió dels estudiants i, a més, també aplicarem contrast d'hipòtesi per respondre a la nostra pregunta de recerca:

> Hi ha una diferència estadísticament significativa entre la proporció d'individus deprimits de cada gènere?

I la respondrem formulant la hipòtesi que són iguals i aplicant contrast d'hipòtesis sobre:

$$
H_0 : p_{home} = p_{dona}
$$

Abans de començar amb el codi, instal·lem i importem les llibreries que farem servir:

```{r setup}
# Instal·lacio de paquets
# install.packages("caret")
# install.packages("cluster")
# install.packages("corrplot")
# install.packages("data.table")
# install.packages("dplyr")
# install.packages("factoextra")
# install.packages("ggplot2")
# install.packages("gridExtra")
# install.packages("kableExtra")
# install.packages("knitr")
# install.packages("mltools")
# install.packages("patchwork")
# install.packages("pROC")
# install.packages("randomForest")
# install.packages("smotefamily")
# install.packages("tidyverse")

## Carregar les llibreries
library(caret)
library(cluster)
library(corrplot)
library(data.table)
library(dplyr)
library(factoextra)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(knitr)
library(mltools)
library(patchwork)
library(pROC)
library(randomForest)
library(smotefamily)
library(tidyverse)
```

# 1. Carregar i preparar les dades

Per tal de carregar les dades hem descarregat l'arxiu `csv` del [dataset triat](https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset) i l'hem desat a la carpeta `/data`. Si inspeccionem l'arxiu veiem que la primera fila correspon als noms de les columnes i que el separador usat és ",". Per llegir les dades fem servir la funció [`read.csv`](https://www.rdocumentation.org/packages/COVID19/versions/2.0.3/topics/read.csv) i indiquem que volem prendre la primera fila com a headers i també marquem `stringsAsFactors = FALSE`: no s'aconsella convertir les cadenes a factors, ja que en dificulta el tractament posterior i pot generar errors [[font](https://blog.r-project.org/2020/02/16/stringsasfactors/)]. Seguidament, en mostrem les primeres línies amb la funció `head()` per fer-ne una primera avaluació.

Per tal de mostrar la taula, darem servir la llibreria [kableExtra](https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html#Overview). 

```{r}
df <- read.csv("data/student_depression_dataset.csv", stringsAsFactors = FALSE, sep = ",")

print(paste("Mida del dataset: ", nrow(df), " files i ", ncol(df), " columnes."))

kbl(head(df), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

El dataset triat té les següents columnes, i han recollit valors per gairebé vint-i-vuit mil persones:

* **`id`:** és un identificador numèric per cada usuari.
* **`Gender`:** indica el gènere de cada usuari.                          
* **`Age`:** és l'edat de cada persona del dataset.
* **`City`:** ciutat de residència de la persona entrevistada.                                 
* **`Profession`:** feina a la qual es dediquen.
* **`Academic.Pressure`:** nivell de pressió acadèmica a la qual estan sotmesos.                
* **`Work.Pressure`:** nivell de pressió laboral a la qual estan sotmesos.  
* **`CGPA`:** nota mitjana acumulada de cada estudiant.                                
* **`Study.Satisfaction`:** nivell de satisfacció amb els estudis.
* **`Job.Satisfaction`:** nivell de satisfacció amb la feina.                    
* **`Sleep.Duration`:** hores que dormen cada dia, de mitjana.
* **`Dietary.Habits`:** descriu com són de saludables els seus hàbits alimentaris.
* **`Degree`:** el nivell d'estudis que estan estudiant.
* **`Have.you.ever.had.suicidal.thoughts..`:** és una variable booleana que indica si algun cop han tingut pensaments suicides.
* **`Work.Study.Hours`:** quantitat d'hores mitjana dedicada a estudiar o treballar.
* **`Financial.Stress`:** nivell d'estrès econòmic al qual estan sotmesos.
* **`Family.History.of.Mental.Illness`:** indica si la seva família té un històric de malalties mentals.
* **`Depression`:** Indica, de manera booleana, si experimenta o no depressió.

# 2. Anàlisi explorativa de les dades

A continuació volem entendre com es distribueixen les dades i si tenen alguna anomalia. Comencem investigant com son aquestes dades i identificant els rangs de valors, els diferents valors en cada categoria i la quantitat de nuls que trobem. Això ho aconseguim mitjançant les funcions [`summary`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/summary), [`is.na`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/NA) i [`unique`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unique). Per mostrar-los, de nou, fem servir kableExtra. A més, creem una llista amb les columnes numèriques i una altra amb les categòriques, que ens serà útil més endavant, sense incloure l'id dels usuaris. És interessant destacar que `Sleep.Duration` són intervals i, per tant, es proporciona com a informació categòrica, amb 5 rangs possibles, com veurem a continuació. A més, `Financial.Stress` està sent interpretada com a caràcter:

```{r}
print(paste("Financial.Stress és de tipus: ", class(df[["Financial.Stress"]])))
print(paste("Financial.Stress pren els valors: ", unique(df[["Financial.Stress"]])))
```

Per tant, el transformem en numèric i deixarem els valors "?" com en `NA`.

```{r}
df$Financial.Stress[df$Financial.Stress == "?"] <- NA 
df$Financial.Stress <- as.numeric(df$Financial.Stress)  
```

Observem que la variable `Depression` és numèrica; tot i això, representa una categoria booleana. Tanmateix, decidim deixar que sigui numèrica ja que en els models supervisats, podrem fer servir una regressió i després decidir la categoria comparant aquest valor amb 0.5.

Seguidament, eliminem la columna d'`id` ja que no ens proporciona cap informació:

``` {r}
df <- df %>% select(-id)
```

Finalment, comprovem quantes columnes tenen valors nuls:

```{r}
kbl(t(colSums(is.na(df))), booktabs = TRUE, caption="Quantitat de dades buides") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Veiem que hi ha només tres valors nuls, en la columna `Financial.Stress` cosa positiva; més endavant decidirem com fer-ne imputació. Ara, per analitzar la resta del dataset en detall; separem aquest apartat en dades qualitatives i quantitatives:

```{r}
categorical_columns <-c("Gender", "City", "Profession", "Sleep.Duration", "Dietary.Habits", "Degree", "Have.you.ever.had.suicidal.thoughts..", "Family.History.of.Mental.Illness")
numerical_columns <- c("Age", "Academic.Pressure", "Work.Pressure", "CGPA", "Study.Satisfaction", "Job.Satisfaction", "Work.Study.Hours", "Financial.Stress", "Depression")
```

# 2.1. Anàlisi explorativa de les dades quantitatives

```{r}
kbl(summary(df[, numerical_columns]), booktabs = TRUE, caption="Resum de les dades numèriques") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Si mirem les variables numèriques, observem el següent:

* Pel que fa a l'edat, sembla que hi ha un gran salt entre el tercer quartil i el màxim (vint-i-nou anys); així que segurament trobem alguns valors extrems (__outliars__) aquí. 
* Les columnes que indiquen satisfacció prenen valors entre 0 i 5, i volem destacar com `Job.Satisfaction` té una mitja de 0.000681 i una mediana de 0, valors molt molt baixos. 
* Els valors d'hores d'estudi i feina diàries són entre 0 i 12, amb un rang gran al primer quartil, però cap valor que sembli invàlid.

A continuació mostrem `boxplots` i histogrames per les dades numèriques, per entendre millor la seva distribució. Per aconseguir-ho, farem servir la llibreria `ggplot2`, que incorpora totes les gràfiques, i la llibreria `gridExtra`, que ens permet endreçar-les. Ajustem les mides amb `fig.height=20, fig.width=15` per tal que a l'html generat es vegin bé


```{r, fig.height=20, fig.width=15}
histograms <- list()
boxplots <- list()

for (col in numerical_columns) {
  
  # Histogram
  histograms[[length(histograms) + 1]] <-  ggplot(df, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "white") +
    ggtitle(paste("Histograma de", col))
  
  # Boxplot
  boxplots[[length(boxplots) + 1]] <- ggplot(df, aes_string(y = col)) +
    geom_boxplot(fill = "tomato", outlier.colour = "red", outlier.shape = 16) +
    ggtitle(paste("Boxplot de", col))
}

do.call(grid.arrange, c(histograms, ncol = 3))
do.call(grid.arrange, c(boxplots, ncol = 3))
```

Mirant els histogrames, i boxplots, observem el següent:

* Hi ha columnes que, tot i ser numèriques, només prenen un conjunt de valors molt petits: `Academic.Pressure`, `Work.Pressure`, `Study.Satisfaction`, `Job.Satisfaction` i `Financial.Stress` prenen valors en cinc o sis nivells.
* Les columnes d'edat (`Age`) i nota mitja (`CGPA`) tenen outilars molt pronunciats; ho veiem en els punts que queden fora dels bigotis dels Boxplots.
* La variable objectiu, `Depression`, només pren valors zero i u; i trobem que hi ha aproximadament cinc-mil instàncies més d'usuaris deprimits que no deprimits. Això pot provocar que els nostres models tendeixin a predir `Depression=1`:

```{r}
print(paste("Quantitat de files amb Depression 1 (Yes):", sum(df$Depression == 1)))
print(paste("Quantitat de files amb Depression 0 (No):", sum(df$Depression == 0)))
print(paste("Un model que predís sempre Depression=1 tindria un accuracy = ", sum(df$Depression == 1) / nrow(df) ))
```
Ja que si un model només predís `Depression=1` ja tindria, gairebé, un 0.6% d'accuracy. Per tant, és probable que haguem d'utilitzar estratègies per reduir els falsos positius en els nostres models supervisats.

A més, podem estudiar la correlació entre les variables numèriques:

```{r}
cor_matrix <- cor(df[, numerical_columns], use = "complete.obs", method = "pearson")
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8)
```

Sembla que `Work.Pressure` està relacionat de manera forta i positiva amb `Job.Satisfaction`. Això pot semblar contraintuitiu, ja que sembla indicar que, com més pressió es pateix a la feina, més satisfets estan els usuaris. Per altra banda, la majoria d'usuaris han marcat 0 en ambdues categories:

```{r}
print(paste("Quantitat de files amb Work.Pressure diferent de 0:", sum(df$Work.Pressure != 0)))
print(paste("Quantitat de files amb Job.Satisfaction diferent de 0:", sum(df$Job.Satisfaction != 0)))
print(paste("Quantitat de files amb Work.Pressure i Job.Satisfaction diferent de 0:", sum(df$Job.Satisfaction != 0 & df$Work.Pressure != 0)))
```
I veiem que, dels més de vint-i-set mil, molt pocs usuaris han marcat valors diferents de 0 en aquestes categories (tres i vuit, respectivament), i que tots aquells que han marcat `Work.Pressure` diferent de 0, també han marcat `Job.Satisfaction` diferent de zero. Per tant, aquesta correlació ens diu poc.

A més, com que gairebé cap usuari ha introduït un valor diferent de zero, no té sentit mantenir aquestes columnes al nostre dataset; així doncs, les eliminem.

``` {r}
df <- df %>% select(-Job.Satisfaction)
df <- df %>% select(-Work.Pressure)
numerical_columns <- c("Age", "Academic.Pressure", "CGPA", "Study.Satisfaction", "Work.Study.Hours", "Financial.Stress", "Depression")
```

Per altra banda, sembla que `Academic.Pressure` té una correlació forta i positiva amb la depressió dels usuaris, i que `Financial.Stress` també, seguida de `Work.Study.Hours`. Per acabar, sembla que l'edat té una correlació negativa amb la depressió: com més joves, més propenços a estar deprimits. `Study.Satisfaction` també hi té una correlació negativa: sembla que, com més satisfets estan amb els seus estudis, menys possibilitats tenen d'estar deprimits. A diferènia de `Job.Satisfaction` i `Work.Pressure` veiem en els histogrames que `Academic.Pressure` i `Study.Satisfaction` prenen valors variats i diversos; per tant, aquesta correlació si que ens pot indicar tendències que veurem més endavant en els nostres models.

# 2.3. Anàlisi explorativa de les dades qualitatives

Ara, volem explorar quins valors prenen les variables quantitatives:

```{r}
categorical_values <- sapply(df[, categorical_columns], function(col) paste(unique(col), collapse = ", "))
categorical_df <- data.frame(Variable = names(categorical_values), Unique_Values = unname(categorical_values))

kbl(categorical_df, booktabs = TRUE, caption="Dades categòriques", colnames=categorical_columns) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Trobem que hi ha 5 rangs pel que fa a les hores de son, i quatre per als hàbits alimentaris; i ambdues categories contenen `Others` com a opció. En apartats següents discutirem si ho considerem opció no vàlida i la imputem, o si seguim endavant amb la categoria. El mateix passa amb `Degree`.

Per tractar les variables categòriques, n'haurem de fer _one-hot_ encoding; potencialment utilitzant la funció [`one-hot`](https://www.rdocumentation.org/packages/mltools/versions/0.3.5/topics/one_hot) que proporciona R; i ho farem a l'apartat 3. Per a estudiar-les de manera explorativa mostrem amb `barplots` la distribució de cada una de les variables no-numèriques.

```{r, fig.height=25, fig.width=15}
barplots <- list()

for (col in categorical_columns) {
  # Barplot
  barplots[[length(barplots) + 1]] <- ggplot(df, aes_string(x = col)) +
          geom_bar(fill = "orange") +
          ggtitle(paste("Bar plot de", col)) +
          theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
          coord_flip()
}

do.call(grid.arrange, c(barplots, ncol = 2))
```

Si mirem les variables qualitatives, veiem el següent:

* La quantitat d'homes i dones que han participat a l'estudi és gairebé igual.
* A simple vista, les ciutats no mostren cap tendència.
* La majoria dels entrevistats, com indica el nom del dataset, són estudiants:

```{r}
print(paste("Quantitat d'estidiants:", sum(df$Profession == "Student")))
print(paste("Quantitat de no estidiants:", sum(df$Profession != "Student")))
print(paste("Percentatge d'estidiants:", sum(df$Profession == "Student") / nrow(df) * 100, "%."))
```

* Pel que fa a `Sleep.Duration` i `Dietary.Habits` totes les categories tenen quantitats comparables de respostes, llevat de `Others`, que en té molt poques.
* El grau més comú és `Class 12`, que és l'últim any d'insititut.
* Dos terços dels entrevistats han tingut pensaments suicides.
* Pel que fa a l'històric de malaltis mentals a la família, aproximadament la meitat dels entrevistats han respost que sí.

Amb aquestes dades, decidim eliminar la columna de professió, ja que aporta molt poca informació.

``` {r}
df <- df %>% select(-Profession)
categorical_columns <-c("Gender", "City", "Sleep.Duration", "Dietary.Habits", "Degree", "Have.you.ever.had.suicidal.thoughts..", "Family.History.of.Mental.Illness")
```

# 3. Neteja de les dades

En aquest apartat prestarem atenció a quines anomalies tenen les nostres dades i decidirem com gestionar-les

## 3.1 Imputació

En els apartats anteriors hem vist les següents variables amb valors problemàtics:

* **`Financial.Stress`:** aquesta variable és numèrica i pren valor `NA` tres cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Financial.Stress = 'NA':", sum(is.na(df$Financial.Stress))))
```

En aquest cas, la variable `Financial.Stress` és numèrica i pren només valors enters; tenint en compte la petita quantitat de valors no vàlids la reemplaçem amb la mediana, ja que la mitjana pot ser decimal.

```{r}
df$Financial.Stress[is.na(df$Financial.Stress)] <- median(df$Financial.Stress, na.rm = TRUE)
print(paste("Quantitat de files amb Financial.Stress = 'NA':", sum(is.na(df$Financial.Stress))))
```
* **`Sleep.Duration`:** aquesta variable és categòrica i pren valor `Others` divuit cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Sleep.Duration = 'Others':", sum(df$Sleep.Duration == "Others")))
```

Les opcions de la categoria `Sleep.Duration` són quatre intervals que cobreixen tota la recta real; per tant, el valor `Others` no té sentit. Decidim, en aquest cas, imputar-lo amb el valor més comú, ja que la dada no és quantitativa sinó qualitativa.

```{r}
most_common_sleep_duration <- names(which.max(table(df$Sleep.Duration)))
df$Sleep.Duration[df$Sleep.Duration == "Others"] <- most_common_sleep_duration
print(paste("Quantitat de files amb Sleep.Duration = 'Others':", sum(df$Sleep.Duration == "Others")))
```
* **`Dietary.Habits`:** aquesta variable és categòrica i pren valor `Others` dotze cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Dietary.Habits = 'Others':", sum(df$Dietary.Habits == "Others")))
```

Les opcions de la categoria `Dietary.Habits` són tres nivells segons com de saludables són; per tant, el valor `Others` no té sentit. Decidim, en aquest cas, imputar-lo amb el valor més comú, ja que la dada no és quantitativa sinó qualitativa.

```{r}
most_common_dietary_habits <- names(which.max(table(df$Dietary.Habits)))
df$Dietary.Habits[df$Dietary.Habits == "Others"] <- most_common_dietary_habits
print(paste("Quantitat de files amb Dietary.Habits = 'Others':", sum(df$Dietary.Habits == "Others")))
```
* **`Degree`:** aquesta variable és categòrica i pren valor `Others` trenta-cinc cops en les més de vint-i-set mil files que té el nostre dataset. 

```{r}
print(paste("Quantitat de files amb Degree = 'Others':", sum(df$Degree == "Others")))
```

En aquest cas, però, tot i que la llista d'opcions educatives proporcionades és prou exhaustiva, pot haver-hi usuaris que no encaixin en cap categoria i, per tant, considerem que el valor `Others` és vàlid en aquest context i no realitzem imputació.


## 3.2 Eliminar outliars

Utilitzant els boxplots per avaluar les variables numèriques, trobem que l'edat (`Age`) i nota mitjana `CGPA` tenen outliars molt marcats; per tant, els eliminarem fent servir la tècnica del [rang interquartílic](https://es.wikipedia.org/wiki/Rango_intercuart%C3%ADlico).

```{r outlier-removal}
for (col in c("Age", "CGPA")) {
  Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)
  Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  df <- df[df[[col]] >= lower_bound & df[[col]] <= upper_bound, ]
}
```

Observem com la seva distribució ha canviat:

```{r, fig.height=8, fig.width=15}
histograms <- list()
boxplots <- list()

for (col in c("Age", "CGPA")) {
  
  # Histogram
  histograms[[length(histograms) + 1]] <-  ggplot(df, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "white") +
    ggtitle(paste("Histograma de", col))
  
  # Boxplot
  boxplots[[length(boxplots) + 1]] <- ggplot(df, aes_string(y = col)) +
    geom_boxplot(fill = "tomato", outlier.colour = "red", outlier.shape = 16) +
    ggtitle(paste("Boxplot de", col))
}

do.call(grid.arrange, c(histograms, ncol = 3))
do.call(grid.arrange, c(boxplots, ncol = 3))
```

## 3.3 Transformar variables categòriques

Per tal de treballar amb les variables categòriques, farem [one-hot encoding](https://es.wikipedia.org/wiki/One-hot), ja que és el més aconsellable per a entrenar models després. Farem servir el mètode [`one_hot`](https://www.rdocumentation.org/packages/mltools/versions/0.3.5/topics/one_hot) de la llibreria `mltools`. Consultem la documentació per veure que primer cal transformar-la en una `df.table` i, després, podem aplicar el mètode i mostrar les primeres files del dataset.

```{r}
df <- as.data.table(df)

for (col in categorical_columns) {
  df[[col]] <- as.factor(df[[col]])
}

df_encoded <- one_hot(df, cols = categorical_columns)

kbl(head(df_encoded), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")
```

Comprovem que s'han codificat correctament

# 4. Anàlisi de dades

## 4.1 Model supervisat

En aquest apartat intentarem predir la columna `Depression`, que és categòrica, però només pren els valors 0 i 1. Ho farem de dues maneres:

* Per una banda, com que la columna és numèrica, aplicarem una regressió lineal, ja que la matriu de correlació indica que hi ha algunes variables, com ara la pressió acadèmica, tenen una forta relació lineal amb la variable objectiu. La regressió predirà un valor que nosaltres compararem amb 0.5; si és major, triarem "1" com a valor predit i, en cas contrari, triarem "0".

* Per altra banda, farem servir un Random Forest, que és un model supervisat molt comú per a variables categòriques que combina diversos arbres de decisió per predir les variables objectiu.

### 4.1.1 Partició Train/Test

El primer pas és separar el conjunt de dades entre les que farem servir per entrenar i les que usarem per avaluar; això ho farem utilitzant [createDataPartition](https://www.rdocumentation.org/packages/caret/versions/7.0-1/topics/createDataPartition). Triem el paràmetre `p = 0.8` de manera que farem servir un 80% de les dades per entrenar, i la resta per l'avaluació. A més, per tal que els nostres resultats siguin reproduibles, fixem la `seed` a 100, i mostrem les mides dels datasets resultants.

```{r}
set.seed(100)

train_index <- createDataPartition(df_encoded$Depression, p = 0.8, list = FALSE)

df_train <- df_encoded[train_index, ]
df_test <- df_encoded[-train_index, ]

print(paste("Mida del conjunt d'entrenament: ", nrow(df_train), " files i ", ncol(df_train), " columnes."))
print(paste("Mida del conjunt de test: ", nrow(df_test), " files i ", ncol(df_test), " columnes."))
```
Comprovem que s'han separat com esperàvem.

### 4.1.2 Regressió lineal

Com hem explicat, farem servir regressió lineal per predir la columna `Depression` i després discretitzarem el resultat per tal que encaixi en una de les categories. Per fer-ho, fem servir la funció [`lm`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) d'R.

```{R}
lm_model <- lm(Depression ~ ., data = df_train)
pred_lm <- predict(lm_model, newdata = df_test)
pred_lm_class <- ifelse(pred_lm < 0.5, 0, 1)
```

Ara, compararem aquestes prediccions amb els valors reals; farem servir dues mesures: accuracy i una matriu de confusió. És important tenir en compte que en el conjunt de dades hi ha cinc-mil casos més de depressió que de no depressió, aproximadament; per tant, és probable que el nostre model es decanti a predir sí. Si veiem que això passa, podrem considerar fer servir alguna altra mesura com ara F1 o el [ràtio de falsos positius](https://en.wikipedia.org/wiki/False_positive_rate) per tal que s'adapti millor. També podriem considerar estratègies de sampling per fer la mostra més homogènia. En primer lloc, però, cal avaluar aquests resultats; ho farem fent servir la funció [`confusionMatrix`](https://rdrr.io/cran/caret/man/confusionMatrix.html) de la llibreria `caret`:

``` {r}
confusionMatrix(as.factor(pred_lm_class), as.factor(df_test$Depression))
```
També estudiem la corba ROC i l'àrea sota la mateixa, utilitzant la llibreria [`pRoc`](https://www.rdocumentation.org/packages/pROC/versions/1.18.5). 

```{r}
roc_obj <- roc(df_test$Depression, pred_lm)

plot(roc_obj, main = "Corva ROC for Depression Prediction")

auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))
```
Finalment, estudiem quines columnes han estat més importants:

``` {r}
summary(lm_model)
```
Observem una accuracy de 0.84, prou bona, i la matriu de confusió ens indica que la quantitat de falsos positius és lleugerament  superior a la de falsos negatius; és a dir, el nostre model tendeix a predir "Depression=1" més del que seria ideal. Per altra banda, la corva ROC té molt bona pinta, i queda sota seu un àrea de 0.94, que és un valor molt bo.

Pel que fa als coeficients, observarem quins tenen un coeficient més gran i, alhora, un p-valor petit. En aquesta categoria trobem `Academic.Pressure` (coeficient 0.1080479, p-valor < 2e-16 ), `Dietary.Habits_Healthy`(coeficient -0.1311164, p-valor < 2e-16 ), i `Have.you.ever.had.suicidal.thoughts.._No`(coeficient -0.3821575, p-valor < 2e-16 ). Això ens explica que la pressió acadèmica influencia positivament a que el resultat sigui de depressió, mentre que els hàbits alimentaris saludables i la manca de pensaments suicides ho influencien negativament. També volem destacar aquelles columnes amb un coeficient major que 0.05 en valor absolut: `Financial.Stress`, `Sleep.Duration_'Less than 5 hours'` (que tenen influència positiva) i `Dietary.Habits_Moderate` (que té influència negativa). Finalment, `Sleep.Duration_'5-6 hours'`, `Sleep.Duration_'7-8 hours'` i `Work.Study.Hours` afecten lleugera i positivament, mentre que `Study.Satisfaction`, `Family.History.of.Mental.Illness_No` i `Age`, negativament.

En aquest cas, com que els casos de `Depression=1` no són més que el doble dels de `Depression=0`, no s'aconsella fer oversampling; i els mètodes més comuns per fer-lo  [`SMOTE`](https://www.rdocumentation.org/packages/smotefamily/versions/1.4.0/topics/SMOTE) no ho suporten. Per tant, decidim intentar-ho amb un model equilibrat, com és el Random Forest, i veure com afecta al resultat.

### 4.1.3 Random Forest

Ara, farem la predicció amb un [Random Forest](https://en.wikipedia.org/wiki/Random_forest), que ens permetrà veure relacions no lineals, ja que combina diferents arbres de precisió i, a més, sol donar bons resultats en dades mixtes com les que tenim. Farem servir la funció [`randomForest`](https://www.rdocumentation.org/packages/randomForest/versions/4.7-1.2/topics/randomForest) que ens proporciona R i ho avaluem de nou amb una matriu de confusió. Aprofitem per passar-li el paràmetre `importance = TRUE` i així poder entendre els resultats. També limitem el valor de `ntree` per sota del que pren per defecte (500) per tal d'agilitzar l'execució del codi. 

Ens adonem que algunes columnes tenen caràcters problemàtics per al nostre arbre; així que canviem els seus noms utlilitzant [`make.names`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/make.names). A més, com que volem que l'arbre faci classificació i no predicció, hem de canviar la variable `Depression` a categòrica.


```{r}
colnames(df_train) <- make.names(colnames(df_train))
colnames(df_test)  <- make.names(colnames(df_test))
df_train$Depression <- as.factor(df_train$Depression)
df_test$Depression  <- as.factor(df_test$Depression)
```

Un cop preparat, entrenem el model i fem les prediccions.

```{r}
model_rf <- randomForest(Depression ~ ., data = df_train, ntree = 200, importance = TRUE)
pred_rf <- predict(model_rf, newdata = df_test)
```

Com que hem posat el paràmetre `importance = TRUE`, podem veure la importància de cada variable a més d'avaluar els resultats amb la nostra matriu de confusió.

```{r}
kbl(importance(model_rf), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")

confusionMatrix(pred_rf, df_test$Depression)
```

En aquest cas, veiem que l'accuracy ha passat a valdre: 0.83, inferior al que havíem obtingut amb una simple regressió lineal. Això ens fa pensar que hi ha alguna columna que pot estar aportant molt de soroll; si observem la taula anterior, veiem que hi ha moltes columnes, com ara les corresponents a les ciutats, que tenen valors negatius a `MeanDecreaseAccuracy`. Això vol dir que, si les eliminem, l'accuracy del nostre model pujarà. Per tant, eliminem aquestes, juntament amb aquelles que fan que l'accuracy no pugi més que 1, ja que poden estar afegint soroll.

```{r}
imp <- importance(model_rf)
imp_df <- as.data.frame(imp)
imp_df$Feature <- rownames(imp_df)
selected_features <- imp_df$Feature[imp_df$MeanDecreaseAccuracy > 1]

# Afegim la variable objectiu (target) a la selecció
selected_features <- c(selected_features, "Depression")

print(selected_features)
```
Extraiem aquestes columnes del nostre dataset.

```{r}
df_train_selected <- df_train[, ..selected_features]
df_test_selected  <- df_test[, ..selected_features]
```

Amb només aquestes columnes, tornem a entrenar el nostre random forest, i avaluem els resultats.

```{r}
model_rf <- randomForest(Depression ~ ., data = df_train_selected, ntree = 200, importance = TRUE)
pred_rf <- predict(model_rf, newdata = df_test_selected)

kbl(importance(model_rf), booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down")) %>%
  scroll_box(width = "900px")

confusionMatrix(pred_rf, df_test_selected$Depression)
```

I l'accuracy ha pujat fins a 0.84; tot i això, el nostre model lineal ha donat millors resultats.

Si mirem els valors d'importància, trobem que `Academic.Pressure` té el més alt, amb diferència, seguit de `Financial.Stress` i `Age`. `Work.Study.Hours`, `Dietary.Habits_Unhealthy`, `Study.Satisfaction` i la presència o no de pensaments suicides, també tenen una importància gran.

## 4.2 Model no supervisat: clustering d'estudiants

### 4.2.1 Preparació del dataset per a l’anàlisi de clústers
```{r}
# Crear df_cluster amb les columnes seleccionades per a l'anàlisi de clústers
df_cluster <- df %>%
  select(Gender, Age,
         Academic.Pressure,
         CGPA, Study.Satisfaction,
         Sleep.Duration, Dietary.Habits,
         Have.you.ever.had.suicidal.thoughts..,
         Work.Study.Hours, Financial.Stress,
         Family.History.of.Mental.Illness, Depression)
```

Per a la construcció del dataframe `df_cluster` destinat a l’anàlisi de clústers, s’han seleccionat variables que aporten informació rellevant i mesurable sobre les característiques dels individus en relació amb el seu estat psicològic i factors associats.

S’han exclòs variables qualitatives com **Degree** o **City**, ja que presenten una gran varietat de categories amb poca relació directa amb els aspectes d’interès per a l’anàlisi, i la seva inclusió podria generar un excés de soroll (*noise*) que dificultaria la identificació de patrons clars. Aquestes variables tendeixen a dispersar la informació i a augmentar la complexitat del model sense aportar un valor predictiu o descriptiu significatiu.

D’aquesta manera, el dataframe final inclou variables demogràfiques, acadèmiques, de salut mental i d’hàbits de vida que són més susceptibles de definir grups homogeni amb característiques comunes i que contribueixen a obtenir clusters més interpretables i robustos.

### 4.2.2 Neteja i escalat de les dades
```{r}
# Escalem totes les columnes perquè tinguin mitjana 0 i desviació estàndard 1
# Això evita que les variables amb escales més grans tinguin més pes en l'anàlisi

# Definim les columnes categòriques a codificar excloent-ne Degree i City
categorical_columns_to_encode <- setdiff(categorical_columns, c("Degree", "City"))

# Apliquem codificació one-hot a les columnes categòriques seleccionades
df_cluster_encoded <- one_hot(df_cluster, cols = categorical_columns_to_encode)

# Apliquem l'escalat estàndard a totes les columnes del conjunt de dades
df_scaled <- as.data.frame(scale(df_cluster_encoded))

# Busquem columnes que tinguin el mateix valor en totes les files
cols_constants <- names(df_scaled)[sapply(df_scaled, function(x) length(unique(x)) <= 1)]
cat("Columnes constants que s'eliminaran:\n")
print(cols_constants)

# Eliminem les columnes que no varien i per tant no aporten informació útil
df_scaled <- df_scaled[, !(names(df_scaled) %in% cols_constants)]
cat("Columnes eliminades per ser constants:", length(cols_constants), "\n")

# Eliminem les files que contenen valors no finits com NA, NaN o Inf
files_inicials <- nrow(df_scaled)
df_scaled <- df_scaled[apply(df_scaled, 1, function(x) all(is.finite(x))), ]
files_eliminades <- files_inicials - nrow(df_scaled)
cat("Files eliminades per ser NA, NaN o Inf:", files_eliminades, "\n")
```

### 4.2.3 Mètode del colze per determinar k

```{r}
# Apliquem el mètode del colze per calcular el WSS per a valors de k de l'1 al 10
set.seed(321)
wss <- map_dbl(1:10, function(k) {
  kmeans(df_scaled, centers = k, nstart = 10)$tot.withinss
})

# Representem gràficament el WSS per veure el punt del colze i determinar el k òptim
plot(1:10, wss, type = "b", pch = 19,
     xlab = "Nombre de clústers (k)",
     ylab = "Total Within Sum of Squares",
     main = "Mètode del colze")
```

### 4.2.4 Anàlisi dels resultats del mètode del colze (WSS - Within Sum of Squares)

```{r }
print(wss)
```

Observem que la disminució del `WSS` és significativa des de `k = 1` fins a `k = 5`, període en què passa de `557580.0` a `413077.9`. Aquesta reducció indica que l'increment de clústers dins d’aquest interval millora notablement la cohesió interna dels grups.

Tot i això, la reducció entre `k = 5` i `k = 6` (de `413077.9` a `397168.7`) continua sent considerable, cosa que suggereix una millora addicional en la compactació dels grups.

A partir de `k = 6`, les reduccions successives en el `WSS` són molt més petites (per exemple, de `397168.7` a `388369.2` en `k = 7`), fet que indica que l’aportació de nous clústers més enllà de `k = 6` és marginal.

Aquest patró mostra que la major part de la millora en la cohesió dels clústers s’aconsegueix amb `6` clústers.

Per tant, el mètode del colze recomana seleccionar `k = 6`, ja que representa un bon equilibri entre la reducció significativa de la variància interna i la simplicitat del model. Afegir més clústers després de `k = 6` no aporta beneficis substancials.

### 4.2.4 Aplicació de k-means amb k = 6  

```{r}
set.seed(123)
kmeans_model <- kmeans(df_scaled, centers = 6, nstart = 25)
df_cluster$cluster <- as.factor(kmeans_model$cluster)
```

A partir de l’anàlisi prèvia mitjançant el mètode del colze, hem determinat que el nombre òptim de clústers per segmentar les dades és `k=6`.

### 4.2.5 Valors mitjans de les variables quantitatives de cada clúster

```{r}
df_cluster %>%
  group_by(cluster) %>%
  summarise(
    Age_mean = mean(Age, na.rm = TRUE),
    CGPA_mean = mean(CGPA, na.rm = TRUE),
    Work.Study.Hours_mean = mean(Work.Study.Hours, na.rm = TRUE),
    Academic.Pressure_mean = mean(Academic.Pressure, na.rm = TRUE),
    Study.Satisfaction_mean = mean(Study.Satisfaction, na.rm = TRUE),
    Financial.Stress_mean = mean(Financial.Stress, na.rm = TRUE),
    Depression_mean = mean(Depression, na.rm = TRUE),
    n = n()
  ) %>%
  kbl(digits = 2, caption = "Valors mitjans per clúster") %>%
  add_header_above(c(
    " " = 1,
    "Demografia" = 1,
    "Rendiment" = 2,
    "Pressió" = 1,
    "Satisfacció i Estrès" = 2,
    "Depressió" = 1,
    "n" = 1
  )) %>%
  kable_styling(
    font_size = 11,
    full_width = FALSE,
    bootstrap_options = c("striped", "hover"),
    position = "center"
  )

```

Els resultats dels clústers mostren una associació clara entre nivells elevats de pressió acadèmica i estrès financer amb un augment del nivell mitjà de depressió.

Els clústers `2`, `3`, `5` i `6` presenten valors més alts en pressió acadèmica (`3.34`, `3.41`, `3.54` i `3.43` respectivament), estrès financer (`3.32`, `3.38`, `3.41` i `3.39`) i depressió mitjana (`0.75`, `0.78`, `0.82` i `0.81`). Aquest patró suggereix que aquests factors podrien contribuir significativament a un major malestar emocional en aquests grups d’estudiants.

En canvi, els clústers `1` i `4` reflecteixen situacions més favorables, amb nivells més baixos tant d’estrès financer (`2.72` i `2.71`) com de depressió (`0.22` en ambdós casos), així com una satisfacció amb els estudis lleugerament superior (`3.13` i `3.10`). Aquests grups poden representar estudiants amb un millor estat de benestar psicològic i una càrrega acadèmica i financera més manejable.

Aquestes observacions reforcen la importància de factors com la pressió acadèmica i l’estrès econòmic com a possibles predictors del benestar mental entre els estudiants analitzats.

### 4.2.6 Distribucions de variables qualitatives

```{r echo = FALSE}

# Depression
df_cluster %>%
  group_by(cluster, Depression) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Depression, y = prop, fill = Depression)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Depression per clúster")
```

Com s’ha observat prèviament, els **clústers 2, 3, 5 i 6** són els que concentren el **nombre més elevat d’individus amb nivells alts de depressió**, fet que coincideix amb uns valors mitjans més alts de **pressió acadèmica** i **estrès financer** en aquests grups. 

```{r echo = FALSE}
# Pensaments suïcides
df_cluster %>%
  group_by(cluster, Have.you.ever.had.suicidal.thoughts..) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Have.you.ever.had.suicidal.thoughts.., y = prop, fill = Have.you.ever.had.suicidal.thoughts..)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Pensaments suïcides per clúster")

df_cluster %>%
  group_by(cluster, Gender) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Gender, y = prop, fill = Gender)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Gender per clúster")

# Family History of Mental Illness
df_cluster %>%
  group_by(cluster, Family.History.of.Mental.Illness) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Family.History.of.Mental.Illness, y = prop, fill = Family.History.of.Mental.Illness)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Family History of Mental Illness per clúster")

# Sleep Duration
df_cluster %>%
  group_by(cluster, Sleep.Duration) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Sleep.Duration, y = prop, fill = Sleep.Duration)) +
  geom_col() +
  facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Distribució de Sleep Duration per clúster")
```

### 4.2.7 Conclusions variables qualitatives

L’anàlisi de les variables qualitatives per clúster reforça els patrons observats en les variables quantitatives, especialment en relació amb la salut mental i el benestar emocional dels estudiants.

Una observació destacada és la variable **“Have you ever had suicidal thoughts”**. Els **clústers 2, 3, 5 i 6**, que ja mostraven valors mitjans més alts de **depressió**, **estrès financer** i **pressió acadèmica**, són també els que concentren una **proporció més elevada d’individus que han afirmat haver tingut pensaments suïcides**. Aquesta coincidència apunta cap a un perfil de **major vulnerabilitat psicològica** en aquests grups.

D’altra banda, els **clústers 1 i 4** presenten proporcions més altes d’estudiants que **no han experimentat pensaments suïcides**, en línia amb els seus valors més baixos de depressió i estrès. Aquests clústers podrien representar estudiants amb més **resiliència emocional** o **entorns menys adversos**.

Pel que fa a la variable **“Sleep Duration”**, es detecta que els clústers amb més casos de depressió (**2,3, 5 i 6**) presenten també una **major proporció d’individus que dormen menys de 5 hores per nit**, i menys que dormin més de 8 hores. Aquesta dada suggereix una possible **relació entre privació de son i malestar emocional**.

Altres variables com **“Gender”** o **“Family History of Mental Illness”** no semblen mostrar diferències clares entre clústers ni aportar informació significativa per a la segmentació, segons l’anàlisi visual realitzada.

Aquestes troballes posen de manifest com certes **variables qualitatives poden complementar de manera rellevant les conclusions derivades de les dades quantitatives**, ajudant a perfilar grups de risc i identificar necessitats específiques en la població estudiada.

# 5. Contrast d'hipòtesis entre Gender i Depression

## 5.1 Proporció Dones/Homes amb o sense Depressió

```{r }
# Trobar les proporcions de Dones/Homes amb o sense Depressió
df_prop <- df %>%
  group_by(Gender, Depression) %>%
  summarise(count = n()) %>%
  mutate(prop = count / sum(count))  # proporció dins de cada gènere

# Canvio els valors 0/1 per No/Sí
df_prop$Depression <- factor(df_prop$Depression, labels = c("No", "Sí"))
print(df_prop)

# Mostro el gràfic amb les proporcions Dones/Homes amb o sense Depressió
ggplot(df_prop, aes(x = Gender, y = prop, fill = Depression)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proporció de depressió segons el gènere",
       x = "Gènere",
       y = "Proporció (%)",
       fill = "Depressió") +
  scale_fill_manual(values = c("darkseagreen3", "indianred2")) +
  theme_minimal()
```

Pel que fa a la distribució de depressió, s’observa que un **58,5% de les dones** i un **58,7% dels homes** presenten depressió, mentre que un **41,5% de les dones** i un **41,3% dels homes** no en tenen. Aquestes proporcions gairebé idèntiques indiquen que, tot i les diferències en la mida de la mostra per gènere, la probabilitat de tenir depressió és pràcticament la mateixa en ambdós grups.

## 5.2 Contrast d'hipòtesis de dues proporcions 

Utilitzarem aquest contrast per determinar si existeix una **diferència significativa** entre les proporcions de dos grups independents. En el nostre cas, volem saber si la **proporció de persones amb depressió** difereix entre **homes i dones**.

Aquest test es basa en la **distribució binomial**, ja que la variable d’interès (**presència o no de depressió**) és binària. Quan la **mida de la mostra** és prou gran, el **teorema del límit central** garanteix que la distribució de la proporció mostral s’aproxima a una **distribució normal**. Aquesta aproximació permet aplicar un test basat en la distribució normal per comparar les proporcions.

A diferència d’altres proves estadístiques, en el test de proporcions **no cal verificar la normalitat ni la homogeneïtat de la variància**, ja que el model parteix de la **distribució binomial** i l’aproximació normal que en deriva.

En aquest estudi, amb una mostra superior a **20.000 registres**, es compleixen àmpliament aquestes condicions, cosa que fa que el test de proporcions sigui una eina **robusta** per avaluar si la proporció de depressió difereix significativament entre homes i dones.

Per això, plantegem el següent **contrast d’hipòtesis** per avaluar l’associació entre gènere i presència de depressió:

**Hipòtesi nul·la ($H_0$):**  
No hi ha diferències en la proporció de persones amb depressió entre homes i dones.

$$
H_0 : p_{home} = p_{dona}
$$

**Hipòtesi alternativa ($H_1$):**  
Hi ha una diferència significativa en la proporció de persones amb depressió entre homes i dones.

$$
H_1 : p_{home} \ne p_{dona}
$$
```{r }
# Persones amb depressió per gènere
depression_male <- sum(df$Gender == "Male" & df$Depression == 1)
depression_female <- sum(df$Gender == "Female" & df$Depression == 1)

# Total Homes/Dones
total_male <- sum(df$Gender == "Male")
total_female <- sum(df$Gender == "Female")

# Contrast d'hipòtesis de proporcions
test_resultat <- prop.test(
  x = c(depression_male, depression_female),
  n = c(total_male, total_female),
  correct = FALSE,
  conf.level = 0.95
)

print(test_resultat)
```

El contrast d’hipòtesis no proporciona evidència estadística suficient per rebutjar la hipòtesi nul·la ($H_0$). Amb un valor de $p = 0.7578$, superior al nivell de significació ($\alpha = 0{,}05$), no es pot afirmar que hi hagi diferències significatives en la proporció de persones amb depressió entre homes i dones.

# Conclusions 

> TODO

> Ha d'incloure com/si hem resolt el problema i la pregunta de recerca
